# Strands Agents Getting Started ä¸­ç¯‡ - æ„å»º Agent & Agent as Tool

ä¸Šä¸€ç¯‡ä»‹ç»äº†ä½¿ç”¨Strands Agentsæ„å»ºMCPä¹‹åï¼Œæœ¬ç¯‡è¿›å…¥A2Aè¯é¢˜ã€‚

## ä¸€ã€èƒŒæ™¯

### 1ã€ä»€ä¹ˆæ˜¯A2A

Agent-to-Agent (A2A) åè®®æ˜¯ä¸€ç§å¼€å‘æ ‡å‡†ï¼Œå…è®¸ä½¿ç”¨ä¸åŒæ¡†æ¶ã€ä¸åŒå¼€å‘è¯­è¨€çš„Agentä¹‹é—´è¿›è¡Œäº¤äº’ã€‚

åœ¨æ²¡æœ‰A2Aåè®®ä¹‹å‰ï¼Œé€šå¸¸ä½¿ç”¨å¤šä¸ªAgentæ—¶å€™ï¼Œç”¨æˆ·åº”ç”¨ç¨‹åºå¯èƒ½éœ€è¦åˆ†åˆ«è¿æ¥å¤šä¸ªAgentï¼Œå¹¶äººå·¥ç»„åˆã€ç¼–æ’ä»–ä»¬è°ƒç”¨å’Œä¾å­˜æ€§å…³ç³»ã€‚è¿™æ ·å¸¦æ¥å¼€å‘çš„å¤æ‚åº¦ï¼Œå¦‚ä½•é€‰æ‹©å°è£…å’Œæš´éœ²æ–¹å¼ã€è°ƒç”¨æ•ˆç‡ã€å“åº”å»¶è¿Ÿã€æ‰©å±•ã€äº¤äº’æ€§ã€å®‰å…¨æ–¹ä¾¿éƒ½æœ‰ä¸è¶³ã€‚è€Œä½¿ç”¨A2Aåè®®ï¼Œç”¨æˆ·æ‰€æœ‰çš„è°ƒç”¨é€šè¿‡ä¸€ä¸ªA2A Clientï¼ˆClient Agentï¼‰è¿›è¡Œï¼Œæ›´å¤šæä¾›æœåŠ¡çš„Agentä½œä¸ºA2A Serverï¼ˆRemote Agentï¼‰æ¥å—è®¿é—®ã€‚ä½¿ç”¨A2Aæ–¹å¼ï¼Œæ•´ä¸ªåº”ç”¨ç¨‹åºåœ¨æ ‡å‡†çš„Agentå‘ç°ã€è®¤è¯ã€å®‰å…¨çš„ç®¡æ§ä½“ç³»ä¸‹ï¼ŒAgentä¹‹é—´å…·æœ‰ç‹¬ç«‹æ€§ã€æ˜“äºæ‰©å±•ã€æ»¡è¶³æ•…éšœéš”ç¦»ï¼Œæ‰€æœ‰è°ƒç”¨ä¸ºä¸€æ­¥è°ƒç”¨ï¼Œæ•´ä¸ªåº”ç”¨æœ‰è‰¯å¥½çš„å¥å£®æ€§ã€‚

A2Açš„ä¸»è¦é€šä¿¡åè®®åŒ…æ‹¬JSON-RPCã€gRPCã€HTTP+JSON/RESTç­‰ï¼Œæ”¯æŒHTTPSã€æ”¯æŒStreamingæ–¹å¼ï¼Œæ”¯æŒè¿›è¡Œæ‰©å±•ã€‚

### 2ã€MCPå’ŒA2A

A2Aåè®®ä¸MCPåè®®åˆ†åˆ«åœ¨ä¸åŒå±‚é¢ï¼Œåˆ†å·¥ä¸åŒï¼ŒäºŒè€…å¹¶æ— çŸ›ç›¾ã€‚MCPåè®®å…³æ³¨åœ¨ä½¿ç”¨LLMå¤§è¯­è¨€æ¨¡å‹æ„å»ºä¸€ä¸ªAgentæ—¶å€™çš„Toolå·¥å…·è°ƒç”¨ï¼Œå®ƒä¸ºå•ä¸ªAgentæ™ºèƒ½ä½“å†…éƒ¨çš„æ¨¡å‹å’Œå·¥å…·ä¹‹é—´çš„äº¤äº’æä¾›äº†è§„èŒƒçš„ç®¡é“ï¼Œå…è®¸å¤§é‡ç¬¬ä¸‰æ–¹MCP Serverä½œä¸ºå·¥å…·è¢«æ¥å…¥å¤ç”¨ã€‚ç”±æ­¤ï¼Œä¸€ä¸ªAgentæ™ºèƒ½ä½“èƒŒåå¯èƒ½æœ‰å¤šä¸ªMCP Serveråœ¨æ”¯æ’‘å®ƒçš„è¿è¡Œã€‚ä¸MCPä¸åŒï¼ŒA2Aåè®®å…³æ³¨Agentæ™ºèƒ½ä½“ä¹‹é—´çš„é€šä¿¡è§„èŒƒï¼Œå¤šä¸ªAgentæ™ºèƒ½ä½“ç»„åˆåœ¨ä¸€èµ·ï¼Œå¦‚ä½•äº’ç›¸å‘ç°ã€äº’ç›¸äº†è§£å„è‡ªçš„èƒ½åŠ›ï¼ˆé€šè¿‡Agent Cardç­‰å½¢å¼ï¼‰ã€‚

è¿™é‡Œç”¨æ±½è½¦å”®åç»´ä¿®ç³»ç»Ÿä¸¾ä¸€ä¸ªä¾‹å­ã€‚å®¢æˆ·è¯·æ±‚æ¥è‡ªä¸å®¢æˆ·è´Ÿè´£èŠå¤©å¯¹æ¥çš„Agentï¼ŒAgentåˆ†æå®¢æˆ·çš„å¯¹è¯å†…å®¹ï¼Œåˆ¤æ–­éœ€è¦ä¸ç»´ä¿®é¢„çº¦Agentã€å¤‡ä»¶åº“å­˜Agentã€è®¢å•Agentä¸‰ä¸ªAgentè¿›è¡Œäº¤äº’ï¼Œåˆ†åˆ«æ²Ÿé€šéœ€è¦çš„ä¿¡æ¯ï¼Œå¹¶æœ€ç»ˆå®Œæˆå®¢æˆ·éœ€è¦å†…å®¹çš„æ•´ç†å’Œè¾“å‡ºã€‚åœ¨è¿™ä¸ªç³»ç»Ÿå†…éƒ¨ï¼Œå‡ ä¸ªAgentä¹‹é—´çš„äº¤äº’æ˜¯é€šè¿‡A2Aåè®®å®Œæˆçš„ï¼Œè€Œæ¯ä¸ªAgentè¿˜éœ€è¦è°ƒç”¨åå°æ–‡æ¡£ã€çŸ¥è¯†åº“ã€æ•°æ®åº“ã€å­˜å‚¨ã€æˆ–è€…é€šè¿‡ç½‘ç»œè·å–è¿œç«¯APIä¿¡æ¯æ—¶å€™ï¼Œå°†é€šè¿‡Agentè‡ªèº«é…ç½®çš„MCP Serverï¼Œä»¥MCPåè®®è·å–äº¤äº’æ•°æ®ã€‚MCPåè®®è¿”å›æ•°æ®ç»™Agentåï¼Œæœ¬Agentè¿›è¡Œæ±‡æ€»å’Œç†è§£ï¼Œå†é€šè¿‡A2Aåè®®è¾“å‡ºç»™å…¶ä»–Agentã€‚

ä»ä»¥ä¸Šçš„ä¾‹å­å¯ä»¥çœ‹å‡ºï¼ŒA2Aæ˜¯Agentä¹‹é—´çš„é€šä¿¡è§„èŒƒï¼Œè€ŒMCPåè®®è§£å†³äº†åœ¨å•ä¸ªAgentå†…è°ƒç”¨å¤–éƒ¨å·¥å…·å’Œèµ„æºçš„èƒ½åŠ›ï¼ŒäºŒè€…äº’ç›¸é…åˆæ„å»ºå¤šAgentæ¶æ„ã€‚

### 3ã€Multi-agent

å½“æœ‰å¤šä¸ªAgentå„è‡ªè´Ÿè´£ä¸åŒçš„ä¸šåŠ¡é€»è¾‘ã€å¹¶ç›¸äº’é€šä¿¡æ—¶å€™ï¼Œå¯ä»¥æœ‰å¤šç§æ¶æ„ç»„åˆæ–¹å¼ã€‚ä¸Userç›´æ¥äº¤äº’çš„Agentå¯è¢«ç§°ä½œClient Agentï¼ŒClient Agenté€šå¸¸åªæœ‰1ä¸ªï¼Œè€Œè¢«Client Agentè°ƒç”¨çš„Agentå«åšRemote Agentï¼Œå®ƒä»¬å¯ä»¥æœ‰å¤šä¸ªã€‚åœ¨Client Agentä¸Remote Agentä¹‹é—´çš„è°ƒç”¨å°±æ˜¯A2Aåè®®ã€‚Client Agentä½œä¸ºä¸»è¦çš„Agentï¼Œä¸ä»…ä»…æ˜¯A2Aä¸­çš„Clientï¼Œå®ƒä¹Ÿæ˜¯å…·æœ‰å¤§è¯­è¨€æ¨¡å‹ç†è§£èƒ½åŠ›çš„ã€‚Remote Agentä¹‹é—´å…¶å®æ²¡æœ‰äº¤äº’ï¼Œéƒ½ä¾èµ–Client Agentä¸å®ƒä»¬äº¤äº’å’Œæ±‡æ€»ã€‚

å¦å¤–çš„æ¶æ„æ˜¯Remote Agentä¹‹é—´å¯ä»¥äº¤äº’ï¼Œè¿™ä¸å­˜åœ¨å•ä¸ªClient Agentå±…ä¸­è°ƒåº¦æ‰€ä¸åŒï¼Œå¤šAgentæ¶æ„åœ¨å®ƒä»¬ä¹‹é—´é€šè¿‡A2Aåè®®è¿›è¡Œå‘ç°ï¼Œè·å–å„è‡ªAgentçš„èƒ½åŠ›èŒƒå›´å’Œè¾¹ç•Œï¼Œå¹¶é€šè¿‡Graphã€Swarmã€Workflowç­‰æ–¹å¼è¿›è¡Œäº¤äº’ã€‚è¿™å‡ ç§æ–¹å¼ä¹‹é—´åˆæœ‰ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œå°†åœ¨ä¸‹ä¸€ç¯‡ä¸­è¿›è¡Œè¿‡ä»‹ç»ã€‚

### 4ã€Agent as Tool

åˆšæ‰ä»‹ç»çš„Multi-agentæ¶æ„ä¸­çš„Client Agentå’ŒRemote Agentæ˜¯é€šè¿‡A2Aåè®®åœ¨ç½‘ç»œä¸Šäº¤äº’çš„ï¼Œå®ƒä»¬å¯èƒ½ä½äºä¸åŒçš„ç¯å¢ƒï¼ˆä¸åŒçš„å®¹å™¨ï¼‰ï¼Œç›‘å¬ä¸åŒçš„ç«¯å£å„è‡ªç‹¬ç«‹å·¥ä½œã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ç§æ›´ç®€å•çš„å®ç°æ–¹å¼ï¼Œå°±æ˜¯æŠŠæ‰€æœ‰Remote Agentå’ŒClient Agentéƒ½éƒ¨ç½²åœ¨ä¸€èµ·ï¼Œé€šè¿‡Client Agentä½œä¸º`Orchestrator`çš„è§’è‰²æ¥å¯åŠ¨ã€‚åœ¨å¯åŠ¨ä½œä¸º`Orchestrator`çš„Agentæ—¶å€™ï¼Œå°†å…¶ä»–Agentä½œä¸º`Specialized Tool`çš„æ–¹å¼ç›´æ¥é…ç½®åˆ°Tooluseéƒ¨åˆ†ã€‚åœ¨æ­¤åœºæ™¯ä¸‹ï¼Œè¿™äº›`Specialized Agent`æ˜¯ä¸èƒ½ç‹¬ç«‹è¿è¡Œï¼Œä¹Ÿæ²¡æœ‰å¯¹å¤–æš´éœ²ï¼Œè€Œæ˜¯éƒ½ç¼©è¿›äº†ä¸€å±‚ï¼Œå®Œå…¨è—åœ¨`Orchestrator Agent`çš„èƒŒåã€‚è¿™ç§å®ç°æ–¹å¼ï¼Œå¯¹å¤–åªæš´éœ²å•ä¸€Agentä¹Ÿå°±æ˜¯`Orchestrator Agent`ã€‚è¿™ç§æ–¹å¼è¢«ç§°ä¸º`Agent as Tool`ã€‚

ä¸‹é¢åˆ†åˆ«å‡†å¤‡æ¼”ç¤ºä»£ç ã€‚

## äºŒã€æ„å»ºRemote Agentæ¥å—Client Agentè®¿é—®

æœ¬ä¾‹ä½¿ç”¨ [Strands Agentså®˜æ–¹sampleä»£ç åº“](https://github.com/strands-agents/samples/tree/main/03-integrations/Native-A2A-Support) ä¸­çš„ä¾‹å­ã€‚

### 1ã€ä½¿ç”¨Strands Agentsçš„Python SDKæ„å»ºRemote Agent

å’Œæœ¬æ–‡ä¸Šç¯‡ä¸­çš„åˆå§‹åŒ–è¿‡ç¨‹ä¸€æ ·ï¼Œè¿™é‡Œä¹Ÿè¦åˆå§‹åŒ–ç¯å¢ƒã€‚

```shell
uv init 03-a2a-server-and-client
cd 03-a2a-server-and-client
uv venv
source .venv/bin/activate
uv add strands-agents strands-agents-tools
uv add strands-agents[a2a]
```

ä¸ä¹‹å‰ä»…ä½¿ç”¨MCPä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œåˆå§‹åŒ–è¦é¢å¤–å¢åŠ A2Aéœ€è¦çš„ä¾å­˜åº“ã€‚å› æ­¤å¢åŠ ä¸€æ­¥ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```shell
uv pip install 'strands-agents[a2a]'
```

å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`remote-agent.py`ã€‚å†…å®¹å¦‚ä¸‹ã€‚

```python
import logging
from strands.models import BedrockModel
from strands_tools.calculator import calculator
from strands import Agent
from strands.multiagent.a2a import A2AServer

logging.basicConfig(level=logging.INFO)

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

# Create a Strands agent
strands_agent = Agent(
    name="Calculator Agent",
    model=bedrock_model,
    description="A calculator agent that can perform basic arithmetic operations.",
    tools=[calculator],
    callback_handler=None
)

# Create A2A server (streaming enabled by default)
a2a_server = A2AServer(agent=strands_agent)

# Start the server
a2a_server.serve()
```

ä»¥ä¸Šä»£ç æ„å»ºäº†ä¸€ä¸ªä»¥æ•°å­¦è®¡ç®—å™¨ä¸ºæ ¸å¿ƒçš„æ™ºèƒ½ä½“ï¼Œä½¿ç”¨Claudeæ¨¡å‹ä½œä¸ºèƒŒåçš„LLMå¤„ç†å®¢æˆ·è¾“å…¥è¯·æ±‚ã€‚è¿è¡Œè¿™ä¸ªRemote Agentã€‚

```shell
uv run remote-agent.py
```

è¿è¡ŒæˆåŠŸï¼Œæ§åˆ¶å°è¿”å›ä¿¡æ¯å¦‚ä¸‹ï¼š

```shell
INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials
INFO:strands.multiagent.a2a.server:Strands' integration with A2A is experimental. Be aware of frequent breaking changes.
INFO:strands.multiagent.a2a.server:Starting Strands A2A server...
INFO:     Started server process [88487]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:9000 (Press CTRL+C to quit)
```

ä¸è¦å…³é—­è¿™ä¸ªæ§åˆ¶å°çª—å£ï¼Œä¿æŒå…¶æ‰“å¼€çŠ¶æ€ï¼Œæ–°å¼€ä¸€ä¸ªæ§åˆ¶å°çª—å£ï¼Œç»§ç»­åç»­çš„æ“ä½œã€‚

### 2ã€ä½¿ç”¨A2A NativeåŸç”ŸSDKä½œä¸ºClientå¹¶ä½¿ç”¨Streamingæ–¹å¼è°ƒç”¨

ç”±Strands Agentsç”Ÿæˆçš„Remote Agentsï¼ˆA2A Serverï¼‰æ˜¯éµå¾ªæ ‡å‡†A2Aåè®®çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ä»»ä½•æ”¯æŒA2Aåè®®çš„å®¢æˆ·ç«¯æ¥è®¿é—®ã€‚è¿™é‡Œä½¿ç”¨A2Aç¤¾åŒºå®˜æ–¹çš„Python SDKï¼Œå³`strands-agents-tools[a2a_client]`æ¥æµ‹è¯•ã€‚ä¸‹é¢æ„å»ºä¸€ä¸ªStreaming Clientï¼Œä½¿ç”¨Server-Sent Events (SSE)çš„æ–¹å¼è¿æ¥åˆ°æœåŠ¡å™¨ã€‚

è¿›å…¥ä¸ServeråŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œåˆ›å»º`client-streaming.py`ã€‚å†…å®¹å¦‚ä¸‹ã€‚

```python
import asyncio
import logging
from uuid import uuid4

import httpx
from a2a.client import A2ACardResolver, ClientConfig, ClientFactory
from a2a.types import Message, Part, Role, TextPart

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DEFAULT_TIMEOUT = 300 # set request timeout to 5 minutes

def create_message(*, role: Role = Role.user, text: str) -> Message:
    return Message(
        kind="message",
        role=role,
        parts=[Part(TextPart(kind="text", text=text))],
        message_id=uuid4().hex,
    )

async def send_streaming_message(message: str, base_url: str = "http://127.0.0.1:9000"):
    async with httpx.AsyncClient(timeout=DEFAULT_TIMEOUT) as httpx_client:
        # Get agent card
        resolver = A2ACardResolver(httpx_client=httpx_client, base_url=base_url)
        agent_card = await resolver.get_agent_card()

        # Create client using factory
        config = ClientConfig(
            httpx_client=httpx_client,
            streaming=True,  # Use streaming mode
        )
        factory = ClientFactory(config)
        client = factory.create(agent_card)

        # Create and send message
        msg = create_message(text=message)

        async for event in client.send_message(msg):
            if isinstance(event, Message):
                logger.info(event.model_dump_json(exclude_none=True, indent=2))
            elif isinstance(event, tuple) and len(event) == 2:
                # (Task, UpdateEvent) tuple
                task, update_event = event
                logger.info(f"Task: {task.model_dump_json(exclude_none=True, indent=2)}")
                if update_event:
                    logger.info(f"Update: {update_event.model_dump_json(exclude_none=True, indent=2)}")
            else:
                # Fallback for other response types
                logger.info(f"Response: {str(event)}")

# Usage
asyncio.run(send_streaming_message("what is 101 * 11"))
```

æœ¬ä¾‹Clientçš„ä»£ç å’Œä½œä¸ºRemote Agentçš„ä»£ç æ˜¯åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œå› æ­¤å…ˆéœ€è¦åŠ è½½ä¸‹uvçš„è™šæ‹Ÿç¯å¢ƒã€‚ç”±äºä½¿ç”¨çš„æ˜¯A2A Nativeçš„SDKï¼Œå› æ­¤è¦å®‰è£…ä¸‹`strands-agents-tools[a2a_client]`ã€‚æœ€åæ‰§è¡Œ`python client-agent.py`å¯åŠ¨Client Agentã€‚å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
source .venv/bin/activate
uv pip install 'strands-agents-tools[a2a_client]'
uv run client-agent.py
```

è¿è¡Œåè¿”å›Streamingæ–¹å¼çš„è¾“å‡ºï¼Œå› ä¸ºè¿”å›å†…å®¹é‡è¾ƒå¤§ï¼Œä¸”streamingæ–¹å¼æ˜¯åˆ†ç‰‡çš„ï¼Œè¿™é‡Œå°±ä¸å†ç²˜è´´å®Œæ•´è¿”å›å†…å®¹ç»™äº†ã€‚ç‰‡æ®µå¦‚ä¸‹ï¼š

```shell
{
      "contextId": "af752716-87e2-41cb-baf6-16c5a3f2af4c",
      "kind": "message",
      "messageId": "d8236a84-bd98-4c66-9ed8-fe5df5d2b32f",
      "parts": [
        {
          "kind": "text",
          "text": "by 11,"
        }
      ],
      "role": "agent",
      "taskId": "a4864472-12b7-4c98-9f72-64459e4d8f67"
    },
    {
      "contextId": "af752716-87e2-41cb-baf6-16c5a3f2af4c",
      "kind": "message",
      "messageId": "489ce201-f825-41ae-9d1c-10c87ce3469c",
      "parts": [
        {
          "kind": "text",
          "text": " you get the repe"
        }
      ],
      "role": "agent",
      "taskId": "a4864472-12b7-4c98-9f72-64459e4d8f67"
    },
    {
      "contextId": "af752716-87e2-41cb-baf6-16c5a3f2af4c",
      "kind": "message",
      "messageId": "810eadfb-90a8-4035-a393-b7c2041c3725",
      "parts": [
        {
          "kind": "text",
          "text": "ating digit pattern "
        }
      ],
      "role": "agent",
      "taskId": "a4864472-12b7-4c98-9f72-64459e4d8f67"
    },
```

ç”±æ­¤çœ‹åˆ°ä½¿ç”¨Strands Agentsæ„å»ºçš„Remote Agentå·¥ä½œæ­£å¸¸ï¼Œéµå¾ªåŸç”ŸA2Aåè®®ï¼Œå¯æ¥å—æ»¡è¶³A2Aåè®®çš„å®¢æˆ·ç«¯æ¥è®¿é—®ã€‚

### 3ã€ä½¿ç”¨Strands Agentsæ„å»ºClient Agentè¿›è¡Œå¼‚æ­¥è°ƒç”¨

ä¸Šä¸€ä¸ªä¾‹å­ä½¿ç”¨çš„æ˜¯A2Aç¤¾åŒºè‡ªå·±çš„Native SDKï¼Œç°åœ¨æ¥ä½“éªŒä¸‹Strands Agentsæ„å»ºçš„Client Agentã€‚

æ–°å¼€ä¸€ä¸ªæ§åˆ¶å°çª—å£ï¼Œè¿›å…¥åˆ°åŒæ ·çš„å·¥ä½œç›®å½•ä¸‹ï¼Œåˆ›å»ºClient Agentã€‚å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`client-agent.py`ã€‚å†…å®¹å¦‚ä¸‹ã€‚

```python
import asyncio

from strands.models import BedrockModel
from strands import Agent
from strands_tools.a2a_client import A2AClientToolProvider

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

# initialize collection of A2A tools for the agent
provider = A2AClientToolProvider(known_agent_urls=["http://localhost:9000"])

# initialize agent with tools
agent = Agent(
    model=bedrock_model,
    tools=provider.tools
    )
# you can also invoke the agent in a non-async context
# print(agent("pick an agent and make a sample call to test its functionality"))

# run the agent in an async context
async def main():
    await agent.invoke_async(
        "pick an agent and make a sample call to test its functionality"
    )

# run
asyncio.run(main())
```

æœ¬ä¾‹Client Agentçš„ä»£ç å’Œä½œä¸ºRemote Agentçš„ä»£ç æ˜¯åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œå› æ­¤åªéœ€è¦åŠ è½½ä¸‹uvçš„è™šæ‹Ÿç¯å¢ƒå°±å¯ä»¥äº†ï¼Œä¸éœ€è¦å†é‡å¤å®‰è£…ä¾èµ–åº“ã€‚éšåæ‰§è¡Œ`python client-agent.py`å¯åŠ¨Client Agentã€‚å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
source .venv/bin/activate
uv run client-agent.py
```

è¿è¡Œåè¿”å›ç»“æœå¦‚ä¸‹ï¼š

```shell
I'll help you test an A2A agent's functionality. First, let me check what agents are currently discovered, and if none are available, I'll discover one for testing.
Tool #1: a2a_list_discovered_agents
Great! I can see there's a Calculator Agent already discovered. It has comprehensive mathematical capabilities including basic arithmetic, equation solving, calculus operations, and more. Let me make a sample call to test its functionality with a simple mathematical expression.
Tool #2: a2a_send_message
Perfect! The A2A agent test was successful. Here's what happened:

## Test Results

**Agent:** Calculator Agent (http://127.0.0.1:9000/)

**Test Query:** "Can you calculate the derivative of x^3 + 2x^2 - 5x + 3 with respect to x?"

**Response:** The agent correctly calculated the derivative as **3xÂ² + 4x - 5** and provided a clear explanation:

- The derivative of xÂ³ is 3xÂ²
- The derivative of 2xÂ² is 4x  
- The derivative of -5x is -5
- The derivative of the constant 3 is 0

## Key Observations

1. **Streaming Support**: The agent supports streaming responses, as evidenced by the detailed message history showing the response being built incrementally.
2. **Mathematical Accuracy**: The calculation is mathematically correct, applying the power rule of differentiation properly.
3. **Clear Communication**: The agent provided both the final answer and step-by-step explanation.
4. **Protocol Compliance**: The agent follows the A2A protocol version 0.3.0 with JSONRPC transport
5. **Rich Capabilities**: Based on the agent card, it supports multiple mathematical operations including:
   - Basic arithmetic evaluation
   - Equation solving
   - Calculus (derivatives, integrals)
   - Limits and series expansions
   - Matrix operations

The test demonstrates that the A2A communication protocol is working correctly and the Calculator Agent is functioning as expected with proper mathematical computation capabilities.
```

å¯çœ‹åˆ°è°ƒç”¨æˆåŠŸã€‚

ä»¥ä¸Šç»“æœå¯ä»¥çœ‹åˆ°ï¼ŒStrands Agentså°è£…çš„Client Agentä¸åŸç”ŸA2Aåè®®å…¼å®¹ï¼Œå¯è°ƒç”¨ä»»ä½•æ”¯æŒA2Aåè®®çš„Agentã€‚ä½¿ç”¨Strands Agentsæ„å»ºçš„Client Agentçš„ä»£ç ä¸­ä¸ªï¼ŒæŒ‡å®šäº†BedrockæœåŠ¡çš„Regionå’Œæ¨¡å‹IDï¼Œå› æ­¤è¿™æ®µä»£ç å¹¶éç®€å•çš„A2A Clientï¼Œè€Œæ˜¯A2Aä¸­çš„Client Agentï¼Œåœ¨ä¸Remote Agentè°ƒç”¨è¿‡ç¨‹ä¸­ï¼Œæœ¬èº«ä¹Ÿå…·æœ‰Agentèƒ½åŠ›ã€‚

### 4ã€å°ç»“

ä½¿ç”¨Strands Agentsæ„å»ºå¼€å‘Remote Agentï¼ˆA2A Serverï¼‰å’ŒClient Agentï¼ˆA2A Clientï¼‰ï¼Œæœ‰æ•ˆç®€åŒ–äº†ä»£ç å·¥ä½œé‡ï¼Œå¯å¿«é€Ÿå¼€å‘ä¸Šçº¿ã€‚å¦å¤–ä½¿ç”¨asyncè°ƒç”¨æ–¹å¼æ˜¯å¼‚æ­¥è°ƒç”¨ï¼Œé€‚åˆä»»åŠ¡æ—¶é—´é•¿ã€å¹¶å‘å¤šçš„æƒ…å†µã€‚

## ä¸‰ã€A2A Server & Client ä¾‹å­ - HR Agent

æœ¬æ–‡ä»¥Githubä¸ŠAWSå®˜æ–¹Sampleä»£ç ä»“åº“ä¸­çš„[HR Agent](https://github.com/aws-samples/sample-agentic-ai-demos/tree/main/modules/strands-a2a-inter-agent)ä¸ºä¾‹ã€‚è¿™ä¸ªä¾‹å­æ˜¯ä¸€ä¸ªHR AgentæŸ¥è¯¢å‘˜å·¥ä¿¡æ¯å’ŒæŠ€èƒ½ã€‚HR Agentä½œä¸ºClient Agentæ¥å—ç”¨æˆ·æé—®ï¼ŒèƒŒåæ˜¯ä¸€ä¸ªEmployee Agentè´Ÿè´£æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯ã€‚Employee Agentçš„æ•°æ®æ¥è‡ªMCP Serverï¼ŒMCP Serverä»¥æ•°ç»„æ–¹å¼é¢„å…ˆå‚¨å­˜äº†ä¸€ç»„å‘˜å·¥æ•°æ®ã€‚

### 1ã€æ„å»ºEmployee AgentèƒŒåçš„MCP Server

åˆå§‹åŒ–ç¯å¢ƒã€‚æ‰§è¡Œå¦‚ä¸‹shellè„šæœ¬ã€‚

```shell
uv init 04-agent-as-tool
cd 04-agent-as-tool
uv venv
source .venv/bin/activate
uv add strands-agents strands-agents-tools
```

å‘˜å·¥ä¿¡æ¯å¦‚ä¸‹ã€‚å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`employee_data.py`ã€‚

```python
import random

FIRST_NAMES = ["James", "Mary", "John", "Patricia", "Robert", "Jennifer", "Michael", "Linda", "William", "Elizabeth"]
LAST_NAMES = ["Smith", "Johnson", "Williams", "Brown", "Jones", "Garcia", "Miller", "Davis", "Rodriguez", "Martinez"]

SKILLS = {
    "Kotlin", "Java", "Python", "JavaScript", "TypeScript",
    "React", "Angular", "Spring Boot", "AWS", "Docker",
    "Kubernetes", "SQL", "MongoDB", "Git", "CI/CD",
    "Machine Learning", "DevOps", "Node.js", "REST API", "GraphQL"
}

EMPLOYEES = list({emp["name"]: emp for emp in [
    {
        "name": f"{random.choice(FIRST_NAMES)} {random.choice(LAST_NAMES)}",
        "skills": random.sample(list(SKILLS), random.randint(2, 5))
    }
    for i in range(100)
]}.values())
```

æä¾›å‘˜å·¥ä¿¡æ¯çš„MCP Serverä»£ç å¦‚ä¸‹ã€‚å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`MCP-Server-for-Employee-agent.py`ã€‚

```python
from mcp.server.fastmcp import FastMCP

from employee_data import SKILLS, EMPLOYEES

mcp = FastMCP("employee-server", stateless_http=True, host="0.0.0.0", port=8002)

@mcp.tool()
def get_skills() -> set[str]:
    """all of the skills that employees may have - use this list to figure out related skills"""
    print("get_skills")
    return SKILLS

@mcp.tool()
def get_employees_with_skill(skill: str) -> list[dict]:
    """employees that have a specified skill - output includes fullname (First Last) and their skills"""
    print(f"get_employees_with_skill({skill})")
    skill_lower = skill.lower()
    employees_with_skill = [employee for employee in EMPLOYEES if any(s.lower() == skill_lower for s in employee["skills"])]
    if not employees_with_skill:
        raise ValueError(f"No employees have the {skill} skill")
    return employees_with_skill

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```

å¯åŠ¨è´Ÿè´£æä¾›æ•°æ®çš„MCP Serverã€‚

```shell
uv run MCP-Server-for-Employee-agent.py
```

å¯çœ‹åˆ°MCP Serverå¯åŠ¨æˆåŠŸã€‚

```shell
INFO:     Started server process [88133]
INFO:     Waiting for application startup.
[09/19/25 16:37:22] INFO     StreamableHTTP session manager started                                                                       streamable_http_manager.py:110
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
```

ä¿æŒä¸Šè¿°æ§åˆ¶å°çš„Shellçª—å£è¿è¡Œä¸­ä¸è¦å…³é—­ã€‚å†æ–°å¼€æ–°çš„Shellæ‰§è¡Œåç»­æ“ä½œã€‚

### 2ã€æ„å»ºEmployee Agentä½œä¸ºRemote Agentæä¾›æœåŠ¡

æ„å»ºEmployee Agentçš„Pythonä»£ç å¦‚ä¸‹ã€‚å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`employee-agent.py`ã€‚

```python
import os

from mcp.client.streamable_http import streamablehttp_client
from strands import Agent
from strands.models import BedrockModel
from strands.tools.mcp.mcp_client import MCPClient
from strands.multiagent.a2a import A2AServer
from urllib.parse import urlparse

EMPLOYEE_INFO_URL = os.environ.get("EMPLOYEE_INFO_URL", "http://localhost:8002/mcp/")
EMPLOYEE_AGENT_URL = os.environ.get("EMPLOYEE_AGENT_URL", "http://localhost:8001/")

employee_mcp_client = MCPClient(lambda: streamablehttp_client(EMPLOYEE_INFO_URL))

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

with employee_mcp_client:
    tools = employee_mcp_client.list_tools_sync()

    employee_agent = Agent(
        model=bedrock_model,
        name="Employee Agent",
        description="Answers questions about employees",
        tools=tools,
        system_prompt="when listing employees, abbreviate employee first names and list all their skills"
    )

    a2a_server = A2AServer(
        agent=employee_agent, 
        host=urlparse(EMPLOYEE_AGENT_URL).hostname, 
        port=urlparse(EMPLOYEE_AGENT_URL).port
        )

    if __name__ == "__main__":
        a2a_server.serve(host="0.0.0.0", port=8001)
```

å°†æ–‡ä»¶ä¿å­˜åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œç„¶ååŠ è½½uvçš„è™šæ‹Ÿç¯å¢ƒï¼Œå†å®‰è£…A2Açš„SDKï¼Œæœ€åå¯åŠ¨Agentã€‚

```shell
source .venv/bin/activate
uv add mcp "strands-agents[a2a]" "strands-agents-tools[a2a_client]" uvicorn
uv run employee-agent.py
```

å¯çœ‹åˆ°Employee Agentå¯åŠ¨æˆåŠŸã€‚

```shell
INFO:     Started server process [90618]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
```

ä¿æŒä¸Šè¿°æ§åˆ¶å°çš„Shellçª—å£è¿è¡Œä¸­ä¸è¦å…³é—­ã€‚å†æ–°å¼€æ–°çš„Shellæ‰§è¡Œåç»­æ“ä½œã€‚

### 3ã€æ„å»ºä¸ç”¨æˆ·/äººç±»äº¤äº’çš„Client Agentã€å¹¶è¿æ¥åˆ°Employee Agent

æ„å»ºHR Agentçš„Pythonä»£ç å¦‚ä¸‹ã€‚å°†å¦‚ä¸‹ä»£ç ä¿å­˜ä¸º`HR-agent.py`ã€‚

```python
import os

import uvicorn
from strands import Agent
from strands.models import BedrockModel
from strands_tools.a2a_client import A2AClientToolProvider
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

EMPLOYEE_AGENT_URL = os.environ.get("EMPLOYEE_AGENT_URL", "http://localhost:8001/")

app = FastAPI(title="HR Agent API")

class QuestionRequest(BaseModel):
    question: str

@app.get("/health")
def health_check():
    return {"status": "healthy"}

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

provider = A2AClientToolProvider(known_agent_urls=[EMPLOYEE_AGENT_URL])

agent = Agent(
    model=bedrock_model, 
    tools=provider.tools, 
    system_prompt="Use a2a agents to access information you don't otherwise have access to."
    )

@app.post("/inquire")
async def ask_agent(request: QuestionRequest):
    async def generate():
        stream_response = agent.stream_async(request.question)

        async for event in stream_response:
            if "data" in event:
                yield event["data"]

    return StreamingResponse(
        generate(),
        media_type="text/plain"
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

å°†æ–‡ä»¶ä¿å­˜åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œç„¶ååŠ è½½uvçš„è™šæ‹Ÿç¯å¢ƒï¼Œå†å®‰è£…A2Açš„SDKï¼Œæœ€åå¯åŠ¨Agentã€‚

```shell
source .venv/bin/activate
uv run HR-agent.py
```

å¯åŠ¨æˆåŠŸã€‚

```shell
INFO:     Started server process [92699]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

### 4ã€æ¨¡æ‹Ÿç”¨æˆ·ï¼ˆäººç±»ï¼‰å‘HR Agentæé—®

HR Agentæ˜¯ä»¥åŒ¿åæ–¹å¼å¯åŠ¨å¹¶ç›‘å¬åœ¨0.0.0.0:8000çš„ï¼Œå› æ­¤åœ¨æœ¬æœºä¸Šå¯ä»¥é€šè¿‡CURLç›´æ¥è®¿é—®ã€‚æ„å»ºå¦‚ä¸‹CURLï¼ŒåŒ…å«äººç±»è¯­è¨€æé—®ç»™HR Agentã€‚

```shell
curl -X POST --location "http://localhost:8000/inquire" \
    -H "Content-Type: application/json" \
    -d '{"question": "list employees that have skills related to AI programming"}'
```

ç°åœ¨è§‚å¯Ÿå‡ ä¸ªå¤„äºè¿è¡ŒçŠ¶æ€çš„Serverã€‚

åœ¨MCP Serverçš„æ§åˆ¶å°ä¸Šå¯ä»¥çœ‹åˆ°æŸ¥è¯¢MCP Serverçš„æ—¥å¿—ï¼š

```shell
INFO:     127.0.0.1:60510 - "POST /mcp/ HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:60510 - "POST /mcp HTTP/1.1" 200 OK
[09/19/25 16:44:33] INFO     Terminating session: None                                                                                                                 streamable_http.py:630
INFO:     127.0.0.1:60512 - "POST /mcp/ HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:60512 - "POST /mcp HTTP/1.1" 202 Accepted
                    INFO     Terminating session: None                      
```

åœ¨Employee Agentçš„æ§åˆ¶å°ä¸Šå¯ä»¥çœ‹åˆ°æ‰“å‡ºäº†å¦‚ä¸‹äº¤äº’æ—¥å¿—ï¼š

```shell
Tool #1: get_skills
Here are all the available skills that employees may have:

- TypeScript
- Kotlin
- Git
- JavaScript
- AWS
- Node.js
- Kubernetes
- GraphQL
- CI/CD
- SQL
- Angular
- React
- Python
- DevOps
- Java
- Docker
- MongoDB
- REST API
- Machine Learning
- Spring BootINFO:     127.0.0.1:61672 - "POST / HTTP/1.1" 200 OK

Tool #2: get_employees_with_skill
Here are the employees with Machine Learning skills:

- **J. Jones** - Angular, Machine Learning, Python, Java
- **M. Brown** - Kotlin, Machine Learning, CI/CD, REST API, AWS
- **W. Brown** - Python, SQL, Machine Learning
- **E. Jones** - REST API, Machine Learning, Spring Boot
- **J. Johnson** - Machine Learning, JavaScript, Python, TypeScript
- **J. Jones** - Angular, Machine Learning, Docker
- **P. Smith** - CI/CD, JavaScript, Machine Learning, Kotlin, Git
- **M. Brown** - Java, TypeScript, Machine Learning
- **J. Johnson** - Machine Learning, SQL, Git
- **J. Williams** - Spring Boot, Machine Learning, GraphQL, SQL, Git
- **M. Garcia** - Java, GraphQL, Machine Learning
- **L. Johnson** - SQL, Machine Learning, Kubernetes, GraphQL, Python
- **L. Rodriguez** - JavaScript, Angular, Machine Learning, Kotlin, MongoDB
- **E. Smith** - Machine Learning, CI/CD, DevOps, Java, REST API

In total, 14 employees have Machine Learning skills.INFO:     127.0.0.1:61712 - "POST / HTTP/1.1" 200 OK

Tool #3: get_employees_with_skill
Here are the employees with Python skills:

- **J. Jones** - Angular, Machine Learning, Python, Java
- **M. Miller** - Node.js, Docker, Kubernetes, Python
- **W. Williams** - Kotlin, Python, GraphQL, SQL
- **M. Williams** - CI/CD, Node.js, Python
- **R. Rodriguez** - Python, GraphQL, Docker, Spring Boot, Java
- **W. Brown** - Python, SQL, Machine Learning
- **J. Rodriguez** - Kotlin, Python, React, Node.js
- **J. Johnson** - Machine Learning, JavaScript, Python, TypeScript
- **R. Miller** - Kubernetes, Python
- **R. Martinez** - SQL, Kotlin, Angular, Python
- **E. Williams** - Python, CI/CD, REST API, React, DevOps
- **J. Smith** - Kubernetes, TypeScript, Python, AWS
- **W. Miller** - React, Python
- **M. Williams** - Docker, React, Kubernetes, Python, AWS
- **L. Johnson** - SQL, Machine Learning, Kubernetes, GraphQL, Python
- **M. Rodriguez** - Kubernetes, MongoDB, GraphQL, TypeScript, Python
- **J. Garcia** - Python, TypeScript

In total, 17 employees have Python skills.INFO:     127.0.0.1:61712 - "POST / HTTP/1.1" 200 OK
```

åœ¨è¿™éƒ¨åˆ†æ—¥å¿—ä¸­ï¼Œå¯ä»¥çœ‹åˆ°Employee Agentè°ƒç”¨äº†3æ¬¡Toolï¼Œåˆ†åˆ«è·å–æŠ€èƒ½ã€äººå‘˜ã€å¹¶ç»„åˆåˆé€‚çš„æŠ€èƒ½åˆ°æŸ¥è¯¢ç»“æœä¸­ã€‚ç”±æ­¤å¯ä»¥çœ‹åˆ°Employee Agentä¸MCP Serverçš„å¤šè½®äº¤äº’ï¼Œè¿™æ˜¯Agentæ™ºèƒ½ä½“å…·å¤‡çš„å¤šæ¬¡äº¤äº’çš„èƒ½åŠ›ã€‚

æœ€åæ¥çœ‹HR Agentçš„æ§åˆ¶å°è¾“å‡ºæ—¥å¿—ã€‚

```shell
I'll help you find employees with AI programming skills. First, let me check what A2A agents are available that might have access to employee data.
Tool #1: a2a_list_discovered_agents
Great! I found an Employee Agent that can help with this. It has skills to get employee information and skills data. Let me first get the list of available skills to identify which ones are related to AI programming.
Tool #2: a2a_send_message
Perfect! I can see the available skills. For AI programming, the most relevant skills would be:
- **Machine Learning** (directly AI-related)
- **Python** (commonly used for AI/ML development)

Let me query for employees with these skills. I'll start with Machine Learning since it's most directly related to AI.
Tool #3: a2a_send_message
Now let me also check for employees with Python skills, as Python is commonly used for AI programming:
Tool #4: a2a_send_message
Based on my query to the Employee Agent, here are the employees that have skills related to AI programming:

## **Employees with AI Programming Skills**

### **Machine Learning Skills (14 employees)**
These employees have direct AI/ML expertise:

1. **J. Jones** - Angular, Machine Learning, Python, Java
2. **M. Brown** - Kotlin, Machine Learning, CI/CD, REST API, AWS
3. **W. Brown** - Python, SQL, Machine Learning

# æ—¥å¿—è¾ƒé•¿ï¼Œä»¥ä¸Šä¸ºéƒ¨åˆ†èŠ‚é€‰...
```

ç”±æ­¤å¯ä»¥çœ‹åˆ°HR Agentä¸Employee AgentäºŒè€…ä¹‹é—´é€šè¿‡A2Aåè®®è¿›è¡Œäº†äº¤äº’ã€‚

æœ€åæˆ‘ä»¬æ¥çœ‹ç”¨æˆ·å³äººç±»ä¸HR Agentäº¤äº’çš„ä¿¡æ¯ï¼Œç”±HR Agentæ•´ç†å¹¶é‡å†™ä¹‹åçš„æœ€ç»ˆç»“æœï¼š

```shell
I'll help you find employees with AI programming skills. First, let me check what A2A agents are available that might have access to employee data.Great! I found an Employee Agent that can help with this. It has skills to get employee information and skills data. Let me first get the list of available skills to identify which ones are related to AI programming.Perfect! I can see the available skills. For AI programming, the most relevant skills would be:
- **Machine Learning** (directly AI-related)
- **Python** (commonly used for AI/ML development)

Let me query for employees with these skills. I'll start with Machine Learning since it's most directly related to AI.Now let me also check for employees with Python skills, as Python is commonly used for AI programming:Based on my query to the Employee Agent, here are the employees that have skills related to AI programming:

## **Employees with AI Programming Skills**

### **Machine Learning Skills (14 employees)**
These employees have direct AI/ML expertise:

1. **J. Jones** - Angular, Machine Learning, Python, Java
2. **M. Brown** - Kotlin, Machine Learning, CI/CD, REST API, AWS
3. **W. Brown** - Python, SQL, Machine Learning
4. **E. Jones** - REST API, Machine Learning, Spring Boot
5. **J. Johnson** - Machine Learning, JavaScript, Python, TypeScript
6. **J. Jones** - Angular, Machine Learning, Docker
7. **P. Smith** - CI/CD, JavaScript, Machine Learning, Kotlin, Git
8. **M. Brown** - Java, TypeScript, Machine Learning
9. **J. Johnson** - Machine Learning, SQL, Git
10. **J. Williams** - Spring Boot, Machine Learning, GraphQL, SQL, Git
11. **M. Garcia** - Java, GraphQL, Machine Learning
12. **L. Johnson** - SQL, Machine Learning, Kubernetes, GraphQL, Python
13. **L. Rodriguez** - JavaScript, Angular, Machine Learning, Kotlin, MongoDB
14. **E. Smith** - Machine Learning, CI/CD, DevOps, Java, REST API

### **Python Skills (17 employees total)**
These employees have Python programming skills, which is commonly used for AI development. Some overlap with the ML list above:

**Additional Python developers (not already listed above):**
- **M. Miller** - Node.js, Docker, Kubernetes, Python
- **W. Williams** - Kotlin, Python, GraphQL, SQL
- **M. Williams** - CI/CD, Node.js, Python
- **R. Rodriguez** - Python, GraphQL, Docker, Spring Boot, Java
- **J. Rodriguez** - Kotlin, Python, React, Node.js
- **R. Miller** - Kubernetes, Python
- **R. Martinez** - SQL, Kotlin, Angular, Python
- **E. Williams** - Python, CI/CD, REST API, React, DevOps
- **J. Smith** - Kubernetes, TypeScript, Python, AWS
- **W. Miller** - React, Python
- **M. Williams** - Docker, React, Kubernetes, Python, AWS
- **M. Rodriguez** - Kubernetes, MongoDB, GraphQL, TypeScript, Python
- **J. Garcia** - Python, TypeScript

### **Summary**
- **14 employees** have direct **Machine Learning** skills
- **17 employees** have **Python** programming skills
- Several employees have both ML and Python skills, making them particularly strong candidates for AI programming roles
- The employees with **both Machine Learning and Python** skills are the most qualified for AI programming work

These employees would be your best candidates for AI programming projects, with those having both Machine Learning and Python skills being the most qualified.
```

Agentè¾“å‡ºåˆ°æ­¤ç»“æŸã€‚ä»¥ä¸Šè¿‡ç¨‹å¯ä»¥çœ‹åˆ°ï¼ŒHR Agentå’ŒEmployee Agentå®Œæˆäº†äº¤äº’ï¼Œå¹¶ä¸”æ¯ä¸ªAgentéƒ½åœ¨è‡ªå·±çš„æŠ€èƒ½èŒƒå›´å†…è¿›è¡Œäº†æœ‰æ•ˆçš„ä¿¡æ¯æ±‡æ€»å’Œè¾“å‡ºï¼Œæœ€ç»ˆç”±è´Ÿè´£ä¸ç”¨æˆ·å¯¹æ¥çš„Client Agentå‘ç”¨æˆ·è¿”å›ç»“æœã€‚

## å››ã€Agent as Toolç¤ºä¾‹2ä¸ª

### 1ã€æ—…è¡Œé¡¾é—®ç¤ºä¾‹ï¼ˆè‹±æ–‡ç‰ˆï¼‰

åˆå§‹åŒ–ç¯å¢ƒã€‚æ‰§è¡Œå¦‚ä¸‹shellè„šæœ¬ã€‚

```shell
uv init 05-agent-as-tool/sample-1
cd init 05-agent-as-tool/sample-1
uv venv
source .venv/bin/activate
uv add strands-agents strands-agents-tools
```

å°†å¦‚ä¸‹å†…å®¹ä¿å­˜ä¸º`specialized_agent_as_tool.py`ã€‚

```python
from strands import Agent, tool
from strands.models import BedrockModel

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

# Define a specialized system prompt
RESEARCH_ASSISTANT_PROMPT = """
ä½ æ˜¯ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©ç†ï¼Œç”±äºè¿™æ˜¯æ¼”ç¤ºç¨‹åºï¼Œæˆ‘ä»¬ä¸ä¼šè¿æ¥åˆ°å¤–éƒ¨æ•°æ®åº“æˆ–APIï¼Œæ‰€ä»¥è¯·åŸºäºä½ å·²æœ‰çš„çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚
"""

PRODUCT_RECOMMENDATION_PROMPT ="""
ä½ æ˜¯ä¸ªä¸“ä¸šçš„äº§å“æ¨èåŠ©ç†ã€‚ç”±äºè¿™æ˜¯æ¼”ç¤ºç¨‹åºï¼Œæˆ‘ä»¬ä¸ä¼šè¿æ¥åˆ°å¤–éƒ¨æ•°æ®åº“æˆ–APIï¼Œæ‰€ä»¥è¯·åŸºäºä½ å·²æœ‰çš„çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚
"""

TRIP_PLANNING_PROMPT ="""
ä½ æ˜¯ä¸ªä¸“ä¸šçš„æ—…è¡Œè§„åˆ’åŠ©ç†ã€‚ç”±äºè¿™æ˜¯æ¼”ç¤ºç¨‹åºï¼Œæˆ‘ä»¬ä¸ä¼šè¿æ¥åˆ°å¤–éƒ¨æ•°æ®åº“æˆ–APIï¼Œæ‰€ä»¥è¯·åŸºäºä½ å·²æœ‰çš„çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚
"""

@tool
def research_assistant(query: str) -> str:
    """
    Process and respond to research-related queries.

    Args:
        query: A research question requiring factual information

    Returns:
        A detailed research answer with citations
    """
    try:
        # Strands Agents SDK makes it easy to create a specialized agent
        research_agent = Agent(
            model=bedrock_model,
            system_prompt=RESEARCH_ASSISTANT_PROMPT
        )
        response = research_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in research assistant: {str(e)}"

@tool
def product_recommendation_assistant(query: str) -> str:
    """
    Handle product recommendation queries by suggesting appropriate products.

    Args:
        query: A product inquiry with user preferences

    Returns:
        Personalized product recommendations with reasoning
    """
    try:
        product_agent = Agent(
            system_prompt=PRODUCT_RECOMMENDATION_PROMPT,
            model=bedrock_model
        )
        response = product_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in product recommendation: {str(e)}"

@tool
def trip_planning_assistant(query: str) -> str:
    """
    Create travel itineraries and provide travel advice.

    Args:
        query: A travel planning request with destination and preferences

    Returns:
        A detailed travel itinerary or travel advice
    """
    try:
        travel_agent = Agent(
            system_prompt=TRIP_PLANNING_PROMPT,
            model=bedrock_model
        )
        response = travel_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in trip planning: {str(e)}"
```

å°†å¦‚ä¸‹å†…å®¹ä¿å­˜ä¸º`orchestrator-agent.py`ã€‚

```python
from strands import Agent
from specialized_agent_as_tool import research_assistant, product_recommendation_assistant, trip_planning_assistant
from strands.models import BedrockModel

# Define the orchestrator system prompt with clear tool selection guidance
MAIN_SYSTEM_PROMPT = """
You are an assistant that routes queries to specialized agents:
- For research questions and factual information â†’ Use the research_assistant tool
- For product recommendations and shopping advice â†’ Use the product_recommendation_assistant tool
- For travel planning and itineraries â†’ Use the trip_planning_assistant tool
- For simple questions not requiring specialized knowledge â†’ Answer directly

Always select the most appropriate tool based on the user's query.

å¦‚æœä½ ä½¿ç”¨æŸä¸ªä¸€ä¸ªå·¥å…·å¤±è´¥ï¼Œè¯·æŠŠé‚£ä¸ªtoolç›´æ¥çš„æŠ¥é”™ä¿¡æ¯è¿”å›ç»™ç”¨æˆ·ï¼Œè€Œä¸æ˜¯å°è¯•ç”¨å…¶ä»–å·¥å…·å›ç­”ã€‚
"""

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

# Strands Agents SDK allows easy integration of agent tools
orchestrator = Agent(
    model=bedrock_model,
    system_prompt=MAIN_SYSTEM_PROMPT,
    callback_handler=None,
    tools=[research_assistant, product_recommendation_assistant, trip_planning_assistant]
)

# Example: E-commerce Customer Service System
customer_query = "I'm looking for hiking boots for a trip to Patagonia next month"

# The orchestrator automatically determines that this requires multiple specialized agents
response = orchestrator(customer_query)
print(response)

# Behind the scenes, the orchestrator will:
# 1. First call the trip_planning_assistant to understand travel requirements for Patagonia
#    - Weather conditions in the region next month
#    - Typical terrain and hiking conditions
# 2. Then call product_recommendation_assistant with this context to suggest appropriate boots
#    - Waterproof options for potential rain
#    - Proper ankle support for uneven terrain
#    - Brands known for durability in harsh conditions
# 3. Combine these specialized responses into a cohesive answer that addresses both the
#    travel planning and product recommendation aspects of the query
```

ä¿å­˜å®Œæ¯•åï¼Œæ‰§è¡Œä½œä¸ºå…¥å£çš„`Orchestrator Agent`ã€‚å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
python3 orchestrator-agent.py
```

å¦‚æœæ‰€æœ‰ä½œä¸ºToolçš„agentå·¥ä½œæ­£å¸¸ï¼Œåˆ™ä¼šè¿”å›ç±»ä¼¼ä¿¡æ¯ã€‚ç”±äºåœ¨`Orchestrator Agent`çš„`System Prompt`æç¤ºè¯éƒ¨åˆ†ï¼Œå†™æ˜äº†å¦‚æœæŸä¸ªä½œä¸ºToolçš„AgentæŠ¥é”™ï¼Œåˆ™è¦æ±‚æŠ›å‡ºé”™è¯¯ä¿¡æ¯ã€‚å› æ­¤æ‰§è¡Œåå¦‚æœè¿”å›ç»“æœæ²¡æœ‰åŒ…å«ä»»ä½•Toolé”™è¯¯è¯´æ˜ï¼Œé‚£å°±æ˜¯æ‰€æœ‰Toolå·¥ä½œæ­£å¸¸ã€‚

```shell
Great choice for an adventure in Patagonia! Here are my top recommendations for hiking boots that will handle those challenging conditions:

## **Top Recommendations:**

### **1. Salomon Quest 4D 3 GTX**
- **Best for:** All-around performance in Patagonia's varied terrain
- **Features:** GORE-TEX waterproofing, excellent ankle support, Contagrip outsole for traction
- **Why it's ideal:** Handles rocky terrain and stream crossings well

### **2. La Sportiva Nucleo High GTX**
- **Best for:** Technical terrain and durability
- **Features:** Vibram sole, reinforced toe/heel, excellent waterproofing
- **Why it's ideal:** Built for rugged Patagonian granite and scree

### **3. Scarpa Zodiac Plus GTX**
- **Best for:** Long-distance comfort with technical capability
- **Features:** Superior ankle support, GORE-TEX Extended Comfort, Vibram Pentax Precision sole
- **Why it's ideal:** Excellent for multi-day treks with heavy packs

## **Key Features for Patagonia:**
- **Waterproofing:** Essential for sudden weather changes
- **Ankle support:** Critical for uneven terrain and loose rock
- **Aggressive tread:** For traction on wet rocks and muddy trails
- **Durability:** To withstand sharp granite and thorny vegetation

## **Sizing Tip:**
Get fitted in the afternoon when your feet are naturally swollen, and consider going up half a size to accommodate thicker socks and foot swelling during long hikes.

Would you like specific advice based on which region of Patagonia you're visiting or your experience level?These are excellent recommendations for your Patagonia adventure! The boots I've suggested are all designed to handle Patagonia's unique challenges - from the unpredictable weather and stream crossings to the rugged granite terrain and scree fields.

The **Salomon Quest 4D 3 GTX** is particularly popular among Patagonia hikers for its versatility, while the **La Sportiva Nucleo High GTX** offers exceptional durability for the harsh conditions. The **Scarpa Zodiac Plus GTX** is ideal if you're planning longer multi-day treks.

A few additional considerations for your Patagonia trip:
- Make sure to break in your boots well before the trip
- Pack extra socks and consider bringing gaiters for added protection
- The waterproofing will be crucial given Patagonia's notorious weather changes

Which area of Patagonia are you planning to visit? Torres del Paine, Fitz Roy area, or somewhere else? This could help narrow down the best choice for your specific route and conditions.
```

è¯·æ³¨æ„ï¼šåœ¨ä»¥ä¸Šä¾‹å­ä¸­ï¼Œæ‰€æœ‰Tooléƒ½æ˜¯æ¨¡æ‹Ÿçš„ï¼Œç”±æ‰®æ¼”Toolçš„Agentç›´æ¥è¾“å‡ºï¼Œæ²¡æœ‰è°ƒç”¨å¤–éƒ¨MCPå·¥å…·å»æŸ¥è¯¢çœŸå®ä¿¡æ¯ã€‚å› æ­¤ä»¥ä¸Šä»£ç ä»…ä¾›å­¦ä¹ ç†è§£Agent as Toolçš„æ¶æ„ã€‚å®é™…ç”Ÿäº§ç¯èŠ‚ï¼Œéœ€è¦è‡ªè¡Œå¢åŠ MCP Serverçš„è°ƒç”¨ï¼Œäº†è§£åˆ°çœŸæ­£çš„æ•°æ®æºã€‚

### 2ã€æ—…è¡Œé¡¾é—®ç¤ºä¾‹ï¼ˆä¸­æ–‡ç‰ˆ+èŠå¤©UIï¼‰

ä¸Šä¸€ä¸ªä¾‹å­æ˜¯åœ¨å‘½ä»¤è¡Œç»ˆç«¯ä¸‹æ‰§è¡Œçš„Pythonæ–‡ä»¶çš„ä¾‹å­ã€‚è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªä¾‹å­æ˜¯ä½¿ç”¨äº†Streamlitå›¾å½¢ç•Œé¢äº¤äº’çš„ä¾‹å­ï¼Œå¹¶ä¸”ä½¿ç”¨ä¸­æ–‡Promptä»¥æ›´ç›´è§‚çš„äº¤äº’ã€‚

åˆå§‹åŒ–ç¯å¢ƒã€‚æ‰§è¡Œå¦‚ä¸‹shellè„šæœ¬ã€‚

```shell
uv init 05-agent-as-tool/sample-2
cd init 05-agent-as-tool/sample-2
uv venv
source .venv/bin/activate
uv add strands-agents strands-agents-tools streamlit dotenv
```

å°†å¦‚ä¸‹å†…å®¹ä¿å­˜ä¸º`chat.py`ã€‚

```python
import os
import streamlit as st
from dotenv import load_dotenv
from strands import Agent, tool
from strands_tools import file_write
import time
from strands.models import BedrockModel

# Load environment variables
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç ”ç©¶åŠ©æ‰‹",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æŒ‡å®šä½¿ç”¨Amazon Bedrockä¸Šçš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€ä½¿ç”¨ç‰¹å®šAWS Region
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2"
)

# Custom CSS for better UI
st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #f0f2f6;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #e6f0ff;
        border-bottom: 2px solid #4c8bf5;
    }
    .agent-card {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 20px;
        background-color: #f9f9f9;
    }
</style>
""", unsafe_allow_html=True)

# ä¸ºä¸åŒæ™ºèƒ½ä½“å®šä¹‰ç³»ç»Ÿæç¤º
RESEARCH_ASSISTANT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚ä¸“æ³¨äºæä¾›å¯¹ç ”ç©¶é—®é¢˜çš„äº‹å®æ€§ã€æ¥æºå¯é çš„ä¿¡æ¯ã€‚
å°½å¯èƒ½å¼•ç”¨ä½ çš„ä¿¡æ¯æ¥æºã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

PRODUCT_RECOMMENDATION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“æ¨èåŠ©æ‰‹ã€‚
æ ¹æ®ç”¨æˆ·åå¥½æä¾›ä¸ªæ€§åŒ–çš„äº§å“å»ºè®®ã€‚å°½å¯èƒ½å¼•ç”¨ä½ çš„ä¿¡æ¯æ¥æºã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

TRIP_PLANNING_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡Œè§„åˆ’åŠ©æ‰‹ã€‚
æ ¹æ®ç”¨æˆ·åå¥½åˆ›å»ºè¯¦ç»†çš„æ—…è¡Œè¡Œç¨‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

# å®šä¹‰åè°ƒå™¨ç³»ç»Ÿæç¤º
MAIN_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå°†æŸ¥è¯¢è·¯ç”±åˆ°ä¸“ä¸šæ™ºèƒ½ä½“çš„åŠ©æ‰‹ï¼š
- å¯¹äºç ”ç©¶é—®é¢˜å’Œäº‹å®ä¿¡æ¯ â†’ ä½¿ç”¨ research_assistant å·¥å…·
- å¯¹äºäº§å“æ¨èå’Œè´­ç‰©å»ºè®® â†’ ä½¿ç”¨ product_recommendation_assistant å·¥å…·
- å¯¹äºæ—…è¡Œè§„åˆ’å’Œè¡Œç¨‹ â†’ ä½¿ç”¨ trip_planning_assistant å·¥å…·
- å¯¹äºä¸éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„ç®€å•é—®é¢˜ â†’ ç›´æ¥å›ç­”

å§‹ç»ˆæ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""

# Define agent tools
@tool
def research_assistant(query: str) -> str:
    """
    å¤„ç†å’Œå“åº”ç ”ç©¶æ€§é—®é¢˜ï¼Œæä¾›æœ‰äº‹å®ä¾æ®çš„ä¿¡æ¯ã€‚

    å‚æ•°:
        query: éœ€è¦è§£ç­”çš„ç ”ç©¶é—®é¢˜

    è¿”å›:
        åŒ…å«å¼•è¯çš„è¯¦ç»†ç ”ç©¶ç­”æ¡ˆ
    """
    try:
        research_agent = Agent(
            system_prompt=RESEARCH_ASSISTANT_PROMPT,
            model=bedrock_model
        )
        response = research_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in research assistant: {str(e)}"

@tool
def product_recommendation_assistant(query: str) -> str:
    """
    å¤„ç†äº§å“æ¨èå’Œè´­ç‰©å»ºè®®ç›¸å…³çš„æŸ¥è¯¢ï¼Œæ ¹æ®ç”¨æˆ·åå¥½æå‡ºåˆé€‚çš„äº§å“å»ºè®®ã€‚

    å‚æ•°:
        query: ç”¨æˆ·æœ‰å…³äº§å“çš„è¯¢é—®

    è¿”å›:
        å¸¦æœ‰ç†ç”±çš„ä¸ªæ€§åŒ–äº§å“æ¨è
    """
    try:
        product_agent = Agent(
            system_prompt=PRODUCT_RECOMMENDATION_PROMPT,
            model=bedrock_model
        )
        response = product_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in product recommendation: {str(e)}"

@tool
def trip_planning_assistant(query: str) -> str:
    """
    åˆ›å»ºæ—…è¡Œè®¡åˆ’å’Œå»ºè®®

    å‚æ•°:
        query: åŒ…å«ç›®çš„åœ°å’Œåå¥½çš„æ—…è¡Œè®¡åˆ’è¯·æ±‚

    è¿”å›:
        è¯¦ç»†çš„æ—…è¡Œè¡Œç¨‹æˆ–æ—…è¡Œå»ºè®®
    """
    try:
        travel_agent = Agent(
            system_prompt=TRIP_PLANNING_PROMPT,
            model=bedrock_model
        )
        response = travel_agent(query)
        return str(response)
    except Exception as e:
        return f"Error in trip planning: {str(e)}"

@tool
def summarize_content(content: str) -> str:
    """
    å°†æä¾›çš„å†…å®¹æ€»ç»“ä¸ºç®€æ˜çš„æ ¼å¼ã€‚

    å‚æ•°:
        content: éœ€è¦æ€»ç»“çš„æ–‡æœ¬å†…å®¹

    è¿”å›:
        å†…å®¹çš„ç®€æ´æ‘˜è¦
    """
    try:
        summary_agent = Agent(
            system_prompt="""
            ä½ æ˜¯æ“…é•¿æ€»ç»“å¤æ‚ä¿¡æ¯çš„ä¸“ä¸šäººå£«ï¼Œèƒ½å¤Ÿå°†å…¶æç‚¼ä¸ºæ¸…æ™°ç®€æ´çš„æ‘˜è¦ã€‚
            ä½ çš„ä¸»è¦ç›®æ ‡æ˜¯ä»è¯¦å°½çš„ä¿¡æ¯ä¸­æå–å…³é”®ç‚¹ã€ä¸»è¦è®ºæ®å’Œæ ¸å¿ƒæ•°æ®ã€‚
            ä½ åº”è¯¥åœ¨ä¿æŒåŸå§‹å†…å®¹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œä½¿å…¶æ›´æ˜“äºç†è§£ã€‚
            æ³¨é‡æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶çªå‡ºä¿¡æ¯ä¸­æœ€é‡è¦æ–¹é¢ã€‚
            """,
            model=bedrock_model
        )
        response = summary_agent(f"è¯·ä¸ºè¿™æ®µå†…å®¹åˆ›å»ºä¸€ä¸ªç®€æ´çš„æ‘˜è¦: {content}")
        return str(response)
    except Exception as e:
        return f"Error in summarization: {str(e)}"

# Create the orchestrator agent
@st.cache_resource
def get_orchestrator():
    return Agent(
        system_prompt=MAIN_SYSTEM_PROMPT,
        tools=[
            research_assistant,
            product_recommendation_assistant,
            trip_planning_assistant,
            file_write,
            summarize_content,
        ],
    )

# Streamlit UI
st.title("ğŸ” å¤šæ™ºèƒ½ä½“ç ”ç©¶åŠ©æ‰‹")
st.markdown("""
æœ¬åº”ç”¨å±•ç¤ºäº†ä½¿ç”¨Strands Agentsçš„"æ™ºèƒ½ä½“å³å·¥å…·"æ¨¡å¼ã€‚
ä¸“ä¸šAIæ™ºèƒ½ä½“ååŒå·¥ä½œï¼Œå¸®åŠ©æ‚¨è¿›è¡Œç ”ç©¶ã€äº§å“æ¨èå’Œæ—…è¡Œè§„åˆ’ã€‚
""")

# Initialize session states
if "messages" not in st.session_state:
    st.session_state.messages = []
if "research_history" not in st.session_state:
    st.session_state.research_history = []
if "product_history" not in st.session_state:
    st.session_state.product_history = []
if "travel_history" not in st.session_state:
    st.session_state.travel_history = []
if "current_tab" not in st.session_state:
    st.session_state.current_tab = "Chat"

# åˆ›å»ºä¸åŒåŠŸèƒ½çš„æ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ èŠå¤©", "ğŸ” ç ”ç©¶", "ğŸ›’ äº§å“", "âœˆï¸ æ—…è¡Œ"])

with tab1:
    st.header("ä¸å¤šæ™ºèƒ½ä½“åŠ©æ‰‹èŠå¤©")
    
    # èŠå¤©æ ‡ç­¾é¡µçš„ä¾§è¾¹æ é€‰é¡¹
    st.sidebar.title("èŠå¤©é€‰é¡¹")
    agent_mode = st.sidebar.radio(
        "é€‰æ‹©äº¤äº’æ¨¡å¼:",
        ["ç›´æ¥æŸ¥è¯¢", "é¡ºåºå¤„ç†", "ä¿å­˜ç»“æœ"]
    )
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # è·å–ç”¨æˆ·è¾“å…¥
    query = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

with tab2:
    st.header("ç ”ç©¶åŠ©æ‰‹")
    st.markdown("""
    è¿™ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ä¸“æ³¨äºæä¾›æœ‰äº‹å®ä¾æ®ã€æ¥æºå¯é çš„ä¿¡æ¯ï¼Œä»¥å›åº”ç ”ç©¶é—®é¢˜ã€‚
    """)
    
    research_query = st.text_area("è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜:", height=100, key="research_query")
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("å¼€å§‹ç ”ç©¶", key="research_button"):
            if research_query:
                with st.spinner("æ­£åœ¨ç ”ç©¶ä¸­..."):
                    try:
                        # è°ƒç”¨ç ”ç©¶æ™ºèƒ½ä½“
                        result = research_assistant(research_query)
                        # æ·»åŠ åˆ°å†å²è®°å½•
                        st.session_state.research_history.append({
                            "query": research_query,
                            "result": result,
                            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                        })
                    except Exception as e:
                        st.error(f"é”™è¯¯: {str(e)}")
    with col2:
        if st.button("ç ”ç©¶å¹¶æ€»ç»“", key="research_summarize_button"):
            if research_query:
                with st.spinner("æ­£åœ¨ç ”ç©¶å¹¶æ€»ç»“..."):
                    try:
                        # è°ƒç”¨ç ”ç©¶æ™ºèƒ½ä½“
                        research_result = research_assistant(research_query)
                        # æ€»ç»“ç»“æœ
                        summary = summarize_content(research_result)
                        # æ·»åŠ åˆ°å†å²è®°å½•
                        st.session_state.research_history.append({
                            "query": research_query,
                            "result": f"**æ‘˜è¦:**\n\n{summary}\n\n**å®Œæ•´ç ”ç©¶:**\n\n{research_result}",
                            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                        })
                    except Exception as e:
                        st.error(f"é”™è¯¯: {str(e)}")
    
    # æ˜¾ç¤ºç ”ç©¶å†å²
    if st.session_state.research_history:
        st.subheader("ç ”ç©¶å†å²")
        for i, item in enumerate(reversed(st.session_state.research_history)):
            with st.expander(f"ç ”ç©¶ {i+1}: {item['query'][:50]}... ({item['timestamp']})"):
                st.markdown(item["result"])
                if st.button("ä¿å­˜åˆ°æ–‡ä»¶", key=f"save_research_{i}"):
                    file_name = f"research_results_{time.strftime('%Y%m%d_%H%M%S')}.txt"
                    with open(file_name, "w") as f:
                        f.write(f"é—®é¢˜: {item['query']}\n\n{item['result']}")
                    st.success(f"å·²ä¿å­˜åˆ° {file_name}")

with tab3:
    st.header("äº§å“æ¨èåŠ©æ‰‹")
    st.markdown("""
    è¿™ä¸ªä¸“ä¸šæ™ºèƒ½ä½“æ ¹æ®æ‚¨çš„åå¥½æä¾›ä¸ªæ€§åŒ–çš„äº§å“å»ºè®®ã€‚
    """)
    
    product_query = st.text_area("æè¿°æ‚¨è¦å¯»æ‰¾çš„äº§å“:", 
                                height=100, 
                                placeholder="ä¾‹å¦‚ï¼šæˆ‘éœ€è¦é€‚åˆåˆå­¦è€…çš„èˆ’é€‚ç™»å±±é‹ï¼Œä»·æ ¼åœ¨100ç¾å…ƒä»¥ä¸‹",
                                key="product_query")
    
    if st.button("è·å–æ¨è", key="product_button"):
        if product_query:
            with st.spinner("æ­£åœ¨æŸ¥æ‰¾äº§å“æ¨è..."):
                try:
                    # è°ƒç”¨äº§å“æ¨èæ™ºèƒ½ä½“
                    result = product_recommendation_assistant(product_query)
                    # æ˜¾ç¤ºç»“æœ
                    st.markdown("### æ¨èäº§å“")
                    st.markdown(result)
                    # æ·»åŠ åˆ°å†å²è®°å½•
                    st.session_state.product_history.append({
                        "query": product_query,
                        "result": result,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    })
                except Exception as e:
                    st.error(f"é”™è¯¯: {str(e)}")
    
    # æ˜¾ç¤ºäº§å“æ¨èå†å²
    if st.session_state.product_history:
        st.subheader("å†å²æ¨è")
        for i, item in enumerate(reversed(st.session_state.product_history)):
            with st.expander(f"æŸ¥è¯¢ {i+1}: {item['query'][:50]}... ({item['timestamp']})"):
                st.markdown(item["result"])

with tab4:
    st.header("æ—…è¡Œè§„åˆ’åŠ©æ‰‹")
    st.markdown("""
    è¿™ä¸ªä¸“ä¸šæ™ºèƒ½ä½“æ ¹æ®æ‚¨çš„åå¥½åˆ›å»ºè¯¦ç»†çš„æ—…è¡Œè¡Œç¨‹ã€‚
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        destination = st.text_input("ç›®çš„åœ°:", placeholder="ä¾‹å¦‚ï¼šä¸œäº¬ï¼Œæ—¥æœ¬")
    with col2:
        duration = st.number_input("è¡Œç¨‹å¤©æ•°:", min_value=1, max_value=30, value=7)
    
    interests = st.multiselect("å…´è¶£çˆ±å¥½:", 
                              ["æ–‡åŒ–", "å†å²", "è‡ªç„¶", "å†’é™©", "ç¾é£Ÿ", "è´­ç‰©", "ä¼‘é—²"],
                              ["æ–‡åŒ–", "ç¾é£Ÿ"])
    
    budget = st.select_slider("é¢„ç®—:", options=["ç»æµ", "é€‚ä¸­", "è±ªå"], value="é€‚ä¸­")
    
    additional_info = st.text_area("å…¶ä»–åå¥½æˆ–è¦æ±‚:", 
                                  placeholder="ä¾‹å¦‚ï¼šæºå¸¦å„¿ç«¥æ—…è¡Œï¼Œæ— éšœç¢éœ€æ±‚ç­‰",
                                  height=100)
    
    if st.button("åˆ›å»ºè¡Œç¨‹", key="travel_button"):
        if destination:
            with st.spinner("æ­£åœ¨åˆ›å»ºæ—…è¡Œè¡Œç¨‹..."):
                try:
                    # æ„å»ºæŸ¥è¯¢
                    travel_query = f"ä¸º{destination}åˆ›å»º{duration}å¤©çš„è¡Œç¨‹ã€‚"
                    travel_query += f"å…´è¶£ï¼š{', '.join(interests)}ã€‚é¢„ç®—ï¼š{budget}ã€‚"
                    if additional_info:
                        travel_query += f"é™„åŠ ä¿¡æ¯ï¼š{additional_info}"
                    
                    # è°ƒç”¨æ—…è¡Œè§„åˆ’æ™ºèƒ½ä½“
                    result = trip_planning_assistant(travel_query)
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.markdown("### æ‚¨çš„æ—…è¡Œè¡Œç¨‹")
                    st.markdown(result)
                    
                    # æ·»åŠ åˆ°å†å²è®°å½•
                    st.session_state.travel_history.append({
                        "query": travel_query,
                        "result": result,
                        "destination": destination,
                        "duration": duration,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    })
                except Exception as e:
                    st.error(f"é”™è¯¯: {str(e)}")
    
    # æ˜¾ç¤ºæ—…è¡Œè§„åˆ’å†å²
    if st.session_state.travel_history:
        st.subheader("å†å²è¡Œç¨‹")
        for i, item in enumerate(reversed(st.session_state.travel_history)):
            with st.expander(f"è¡Œç¨‹ {i+1}: {item['destination']} ({item['duration']} å¤©) - {item['timestamp']}"):
                st.markdown(item["result"])
                if st.button("ä¿å­˜è¡Œç¨‹", key=f"save_itinerary_{i}"):
                    file_name = f"{item['destination'].replace(' ', '_')}_itinerary_{time.strftime('%Y%m%d')}.txt"
                    with open(file_name, "w") as f:
                        f.write(f"ç›®çš„åœ°: {item['destination']} ({item['duration']} å¤©)\n\n{item['result']}")
                    st.success(f"å·²ä¿å­˜åˆ° {file_name}")

if query:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": query})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(query)
    
    # Display assistant response
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("Thinking...")
        
        orchestrator = get_orchestrator()
        
        try:
            # Set environment variable to bypass tool consent
            os.environ["BYPASS_TOOL_CONSENT"] = "true"
            
            start_time = time.time()
            
            if agent_mode == "ç›´æ¥æŸ¥è¯¢":
                # ä½¿ç”¨åè°ƒå™¨å¤„ç†æŸ¥è¯¢
                response = orchestrator(query)
                result = str(response)
                
            elif agent_mode == "é¡ºåºå¤„ç†":
                # é¦–å…ˆè¿›è¡Œç ”ç©¶
                research_response = research_assistant(query)
                
                # ç„¶åæ€»ç»“ç ”ç©¶ç»“æœ
                result = summarize_content(research_response)
                result = f"**ç ”ç©¶æ‘˜è¦:**\n\n{result}\n\n**è¯¦ç»†ç ”ç©¶:**\n\n{research_response}"
                
            elif agent_mode == "ä¿å­˜ç»“æœ":
                # å¤„ç†æŸ¥è¯¢å¹¶ä¿å­˜ç»“æœ
                response = orchestrator(query)
                result = str(response)
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                file_name = f"research_results_{time.strftime('%Y%m%d_%H%M%S')}.txt"
                with open(file_name, "w") as f:
                    f.write(result)
                result += f"\n\nç»“æœå·²ä¿å­˜åˆ° {file_name}"
            
            end_time = time.time()
            processing_time = round(end_time - start_time, 2)
            
            # Update placeholder with result
            message_placeholder.markdown(f"{result}\n\n*Processed in {processing_time} seconds*")
            
            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": f"{result}\n\n*Processed in {processing_time} seconds*"})
            
            # If the query is related to research, also add to research history
            if "research" in query.lower() or "information" in query.lower() or "facts" in query.lower():
                st.session_state.research_history.append({
                    "query": query,
                    "result": result,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })
            
            # If the query is related to products, also add to product history
            if "product" in query.lower() or "recommend" in query.lower() or "buy" in query.lower():
                st.session_state.product_history.append({
                    "query": query,
                    "result": result,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })
            
            # If the query is related to travel, also add to travel history
            if "travel" in query.lower() or "trip" in query.lower() or "vacation" in query.lower():
                st.session_state.travel_history.append({
                    "query": query,
                    "result": result,
                    "destination": query.split("to ")[-1].split(" ")[0] if "to " in query else "Unknown",
                    "duration": "7",  # Default duration
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })
            
        except Exception as e:
            error_message = f"Error: {str(e)}"
            message_placeholder.markdown(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})

# æ·»åŠ ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.title("ç ”ç©¶åŠ©æ‰‹")
    
    st.markdown("## æ™ºèƒ½ä½“èƒ½åŠ›")
    st.markdown("""
    - **ç ”ç©¶åŠ©æ‰‹**: æä¾›æœ‰äº‹å®ä¾æ®ã€æ¥æºå¯é çš„ä¿¡æ¯
    - **äº§å“æ¨è**: æ ¹æ®ç”¨æˆ·åå¥½æ¨èäº§å“
    - **æ—…è¡Œè§„åˆ’**: åˆ›å»ºæ—…è¡Œè¡Œç¨‹å¹¶æä¾›å»ºè®®
    - **å†…å®¹æ€»ç»“**: å°†å¤æ‚ä¿¡æ¯æç‚¼ä¸ºç®€æ´æ‘˜è¦
    """)
    
    st.markdown("## ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. åœ¨èŠå¤©è¾“å…¥æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–ä½¿ç”¨ä¸“ä¸šæ ‡ç­¾é¡µ
    2. ä»ä¾§è¾¹æ é€‰æ‹©äº¤äº’æ¨¡å¼
    3. æŸ¥çœ‹æ¥è‡ªç›¸åº”ä¸“ä¸šæ™ºèƒ½ä½“çš„å›åº”
    """)
    
    st.markdown("## å…³äº")
    st.markdown("""
    æœ¬åº”ç”¨å±•ç¤ºäº†ä½¿ç”¨Strands Agentsçš„"æ™ºèƒ½ä½“å³å·¥å…·"æ¨¡å¼ã€‚
    
    æ¯ä¸ªä¸“ä¸šæ™ºèƒ½ä½“éƒ½è¢«å°è£…ä¸ºå¯è°ƒç”¨çš„å‡½æ•°ï¼ˆå·¥å…·ï¼‰ï¼Œå¯ä¾›åè°ƒå™¨æ™ºèƒ½ä½“ä½¿ç”¨ã€‚
    
    è¿™åˆ›å»ºäº†ä¸€ä¸ªå±‚æ¬¡ç»“æ„ï¼Œå…¶ä¸­åè°ƒå™¨å¤„ç†ç”¨æˆ·äº¤äº’å¹¶å†³å®šè°ƒç”¨å“ªä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚
    """)
    
    # æ·»åŠ æ¸…é™¤æŒ‰é’®ä»¥é‡ç½®èŠå¤©
    if st.button("æ¸…é™¤èŠå¤©å†å²"):
        st.session_state.messages = []
        st.experimental_rerun()
```

ä½¿ç”¨Streamlitå¯åŠ¨è¿è¡Œè¿™ä¸ªè„šæœ¬ã€‚

```shell
streamlit run chat.py
```

å‘½ä»¤è¡Œè¿”å›å¦‚ä¸‹ï¼š

```shell

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.238.92:8501

```

ç°åœ¨ç”¨æµè§ˆå™¨è®¿é—®æœ¬æœºçš„`http://localhost:8501`ï¼Œæ¯”æå‡ºé—®é¢˜ï¼Œä¾‹å¦‚`å†å²ä¸Š1860å¹´å‘ç”Ÿäº†ä»€ä¹ˆ`ã€‚ç°åœ¨æŸ¥çœ‹æ§åˆ¶å°ï¼Œå³å¯çœ‹åˆ°æœ‰è°ƒç”¨Toolçš„è®°å½•ã€‚

### 3ã€å°ç»“

é€šè¿‡ä»¥ä¸Šä¾‹å­å¯ä»¥çœ‹å‡ºï¼ŒAgent as Toolçš„æ–¹å¼åªéœ€è¦å¯åŠ¨å•ä¸€çš„æœåŠ¡ã€å¯¹å¤–åªæš´éœ²å•ä¸€çš„Agentï¼Œè€Œå…¶ä»–Agentåœ¨å†…éƒ¨ä½œä¸ºToolå®ŒæˆAgentçš„æœºèƒ½ï¼Œæœ€ç»ˆæ»¡è¶³æ•´ä¸ªAgentå¯¹å¤–è¾“å‡ºçš„éœ€æ±‚ã€‚

## äº”ã€å‚è€ƒèµ„æ–™

ä»€ä¹ˆæ˜¯A2Aã€‚

[https://a2a-protocol.org/latest/topics/what-is-a2a/](https://a2a-protocol.org/latest/topics/what-is-a2a/)

Strands A2A Inter-Agent Sample

[https://github.com/aws-samples/sample-agentic-ai-demos/tree/main/modules/strands-a2a-inter-agent](https://github.com/aws-samples/sample-agentic-ai-demos/tree/main/modules/strands-a2a-inter-agent)

Multi-agent Patterns å¤šAgent designäº¤äº’æ¨¡å¼ã€‚

[https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/multi-agent-patterns/](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/multi-agent-patterns/)

Strands in 5 minnutes - agent-as-tool

[https://github.com/aws-samples/sample-strands-in-5-minutes/tree/main/05_strands_multi_agent/agent-as-tool](https://github.com/aws-samples/sample-strands-in-5-minutes/tree/main/05_strands_multi_agent/agent-as-tool)